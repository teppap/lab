# -*- coding: utf-8 -*-
"""1.NaiveBayes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_cAt6ncDE4MuJTO63adNIeHKEHbfV0Zi
"""

#Start-CELL1---------------------------------------------------------------------------
# =================================================================
# Lab: AI for Cybersecurity - Web Attack Detection
# โมเดล: Naive Bayes
# =================================================================

# ขั้นตอนที่ 1: ติดตั้ง Library ที่จำเป็น
# เราจะใช้ 'datasets' เพื่อโหลดข้อมูลจาก Hugging Face
# และ 'scikit-learn' สำหรับสร้างโมเดล Machine Learning
# เครื่องหมาย ! คือการรันคำสั่งของระบบ (เหมือนใน Command Prompt)
print("--- กำลังติดตั้ง Library ที่จำเป็น... ---")
!pip install datasets scikit-learn -q

print("\n--- ติดตั้งเสร็จสิ้น! ---")
#End-CELL1---------------------------------------------------------------------------

#Start-CELL2---------------------------------------------------------------------------
# ขั้นตอนที่ 2: Import Library ที่ต้องใช้ในโค้ด
# เราจะดึงเครื่องมือต่างๆ ที่ติดตั้งไว้มาเตรียมใช้งาน
import pandas as pd
from datasets import load_dataset
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

print("--- Import Library ทั้งหมดเรียบร้อย ---")
#End-CELL2---------------------------------------------------------------------------

#Start-CELL3---------------------------------------------------------------------------
# ขั้นตอนที่ 3: โหลดชุดข้อมูล (Dataset) จาก Hugging Face
# เราจะใช้ชุดข้อมูล 'YangYang-Research/web-attack-detection'
# ซึ่งมีตัวอย่างคำขอเข้าเว็บไซต์ ทั้งแบบปกติและแบบที่เป็นการโจมตี
print("--- กำลังโหลด Dataset จาก Hugging Face... ---")
dataset = load_dataset("YangYang-Research/web-attack-detection", split='train')

# แปลงเป็น Pandas DataFrame เพื่อให้จัดการง่ายขึ้น
df = pd.DataFrame(dataset)

print(f"--- โหลดข้อมูลสำเร็จ! มีทั้งหมด {len(df)} ตัวอย่าง ---")

# แสดงตัวอย่างข้อมูล 5 แถวแรก
# Label 0: Normal (ปกติ)
# Label 1: Attack (การโจมตี)
print("\n--- ตัวอย่างข้อมูล 5 แถวแรก: ---")
print(df.head())

# แสดงจำนวนข้อมูลในแต่ละประเภท
print("\n--- สัดส่วนของข้อมูล: ---")
print(df['Label'].value_counts())
#End-CELL3---------------------------------------------------------------------------

#Start-CELL4---------------------------------------------------------------------------
# =================================================================
# ขั้นตอนที่ 4 (ปรับปรุงใหม่): เตรียมและปรับสมดุลข้อมูล (Data Balancing)
# =================================================================

# 4.1) แยกข้อมูลตาม Label
# เพื่อให้เราสามารถจัดการข้อมูลแต่ละประเภทได้
df_normal = df[df['Label'] == 0]  # ข้อมูลปกติ (Normal)
df_attack = df[df['Label'] == 1]  # ข้อมูลการโจมตี (Attack)

print(f"--- ข้อมูลเริ่มต้น ---")
print(f"Normal (Label 0) มี: {len(df_normal)} ตัวอย่าง")
print(f"Attack (Label 1) มี: {len(df_attack)} ตัวอย่าง")

# 4.2) กำหนดจำนวนข้อมูลที่ต้องการ และทำการสุ่ม (Down-sampling)
# เราจะใช้จำนวนของ Label ที่น้อยกว่าเป็นเกณฑ์
# เพื่อให้ข้อมูลทั้งสองประเภทมีจำนวนเท่ากัน
sample_size = min(len(df_normal), len(df_attack))

# สามารถกำหนดจำนวนเองได้ที่นี่ (หากต้องการ)
sample_size = 100000 # (ต้องน้อยกว่าจำนวนข้อมูลที่น้อยที่สุด)
print(f"\n--- กำลังปรับสมดุลข้อมูลให้แต่ละ Label มี: {sample_size} ตัวอย่าง ---")

# สุ่มข้อมูลจาก Label ที่มีจำนวนมากกว่าให้เหลือเท่ากับ sample_size
df_normal_sampled = df_normal.sample(n=sample_size, random_state=42)
df_attack_sampled = df_attack.sample(n=sample_size, random_state=42)

# 4.3) รวมข้อมูลที่ปรับสมดุลแล้วกลับเป็น DataFrame เดียวกัน
df_balanced = pd.concat([df_normal_sampled, df_attack_sampled])

# สับเปลี่ยนลำดับข้อมูล (Shuffle) เพื่อให้ข้อมูลคละกัน ไม่เรียงตาม Label
df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)

print("\n--- ปรับสมดุลข้อมูลสำเร็จ! ---")
print(f"ข้อมูลทั้งหมดหลังปรับสมดุล: {len(df_balanced)} ตัวอย่าง")
print(df_balanced['Label'].value_counts())

# แสดงตัวอย่างข้อมูลที่ปรับสมดุลแล้ว
print("\n--- ตัวอย่างข้อมูลหลังปรับสมดุล: ---")
print(df_balanced.head())


# 4.4) แบ่งข้อมูลเป็น Input (X) และ Output (y) จากชุดข้อมูลที่สมดุลแล้ว
X = df_balanced['Sentence']
y = df_balanced['Label']

# 4.5) แบ่งข้อมูลสำหรับ "เทรน" และสำหรับ "ทดสอบ"
# ตอนนี้ข้อมูลของเราสมดุลแล้ว ไม่จำเป็นต้องใช้ stratify=y อีก
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\n--- แบ่งข้อมูลสำหรับเทรน: {len(X_train)} ตัวอย่าง ---")
print(f"--- แบ่งข้อมูลสำหรับทดสอบ: {len(X_test)} ตัวอย่าง ---")


# 4.6) แปลงข้อความเป็นตัวเลขด้วย TF-IDF (เหมือนเดิม)
print("\n--- กำลังแปลงข้อความเป็นตัวเลข (TF-IDF Vectorization)... ---")
vectorizer = TfidfVectorizer(max_features=5000)

X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print("--- แปลงข้อมูลเสร็จสิ้น ---")
print(f"--- ขนาดของข้อมูลเทรนที่แปลงแล้ว: {X_train_tfidf.shape} ---")
#End-CELL4---------------------------------------------------------------------------

#Start-CELL5---------------------------------------------------------------------------
# ขั้นตอนที่ 5: เทรนโมเดล Naive Bayes
# ขั้นตอนนี้คือการ "สอน" โมเดล โดยใช้ข้อมูลที่เตรียมไว้
print("--- เริ่มเทรนโมเดล Naive Bayes... ---")

# สร้างโมเดล Multinomial Naive Bayes ซึ่งเหมาะกับข้อมูลข้อความ
model = MultinomialNB()

# เริ่มการเทรน!
model.fit(X_train_tfidf, y_train)

print("--- เทรนโมเดลสำเร็จ! ---")
#End-CELL5---------------------------------------------------------------------------

#Start-CELL6---------------------------------------------------------------------------
# ขั้นตอนที่ 6: วัดผลความแม่นยำของโมเดล
# เราจะนำข้อมูล "ทดสอบ" ที่โมเดลไม่เคยเห็นมาก่อน มาให้โมเดลลองทาย
# แล้วดูว่ามันทายถูกกี่เปอร์เซ็นต์
import warnings
warnings.filterwarnings("ignore")

print("--- กำลังวัดผลโมเดลด้วยข้อมูลทดสอบ... ---")

# ให้โมเดลทำนายผลจากข้อมูลทดสอบ
y_pred = model.predict(X_test_tfidf)

# คำนวณความแม่นยำ (Accuracy)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nความแม่นยำ (Accuracy): {accuracy * 100:.2f}%")

# แสดงรายงานผลแบบละเอียด (Classification Report)
# - Precision: ในบรรดาที่ทายว่าเป็น Attack, ถูกจริงๆ กี่ %
# - Recall: จาก Attack ทั้งหมด, โมเดลตรวจจับเจอได้กี่ %
# - F1-score: ค่าเฉลี่ยของ Precision และ Recall
print("\n--- Classification Report: ---")
print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Attack (1)']))

# แสดง Confusion Matrix ในรูปแบบกราฟสวยงาม
# เพื่อให้เห็นว่าโมเดลทายผิดพลาดตรงไหนบ้าง
print("\n--- Confusion Matrix: ---")
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])
plt.xlabel('Predicted Label (ผลที่โมเดลทาย)')
plt.ylabel('True Label (ผลเฉลย)')
plt.title('ผลการทำนายของโมเดล')
plt.show()
#End-CELL6---------------------------------------------------------------------------


#Start-CELL7---------------------------------------------------------------------------
# ขั้นตอนที่ 7: นำโมเดลไปใช้งานจริง!
# ลองใส่ข้อความแปลกๆ แล้วให้โมเดลช่วยตัดสินใจว่าเป็น "การโจมตี" หรือไม่

def predict_attack(text):
  """
  ฟังก์ชันสำหรับรับข้อความ แล้วใช้โมเดลที่เทรนแล้วทำนายผล
  """
  print(f"Input: '{text}'")
  # แปลงข้อความที่รับเข้ามาให้เป็นรูปแบบเดียวกับที่ใช้เทรน (TF-IDF)
  text_tfidf = vectorizer.transform([text])
  # ทำนายผล
  prediction = model.predict(text_tfidf)
  # ทำนายความน่าจะเป็น
  probability = model.predict_proba(text_tfidf)

  if prediction[0] == 1:
    print(f"ผลการทำนาย: 🚨 การโจมตี (Attack) 🚨")
    print(f"ความน่าจะเป็นที่จะเป็น Attack: {probability[0][1]*100:.2f}%")
  else:
    print(f"ผลการทำนาย: ✅ ปกติ (Normal) ✅")
    print(f"ความน่าจะเป็นที่จะเป็น Normal: {probability[0][0]*100:.2f}%")
  print("-" * 30)


# --- ลองทดสอบกับตัวอย่างต่างๆ ---

# ตัวอย่าง Traffic ปกติ
predict_attack("GET /home.html HTTP/1.1")
predict_attack("POST /api/users/search?name=prasert HTTP/1.1")

# ตัวอย่างการโจมตีแบบ SQL Injection (พยายามลบข้อมูล)
predict_attack("GET /products?id=1' OR '1'='1'; DROP TABLE users; --")

# ตัวอย่างการโจมตีแบบ Cross-Site Scripting (XSS) (พยายามขโมย cookie)
predict_attack("<script>alert('XSS');</script>")
predict_attack("'><img src=x onerror=alert(document.cookie)>")

#End-CELL7---------------------------------------------------------------------------
